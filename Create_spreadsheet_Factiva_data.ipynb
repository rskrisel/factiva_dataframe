{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rskrisel/factiva_dataframe/blob/main/Create_spreadsheet_Factiva_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collecting news data from Factiva and saving it in a Dataframe"
      ],
      "metadata": {
        "id": "twshZ2KyZoZS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**For detailed instructions on how to collect Factiva data, review this [step by step guide with images](https://docs.google.com/document/d/1C9crxk6kdYJZqU0bEx1UZMxFZpowQe3ESQO_hA1wUK0/edit?usp=sharing)**\n",
        "\n",
        "* Step 1: Locate the `Factiva database` on the `Columbia University website`\n",
        "\n",
        "* Step 2: Enter your search term(s) and click `Search`\n",
        "\n",
        "* Step 3: Click `Display Options` and select `Full Article/Report plus Indexing`\n",
        "\n",
        "* Step 4: Select `Duplicates: Identical`\n",
        "\n",
        "* Step 5: Click the ✅ to select the articles you want to save\n",
        "\n",
        "* Step 6: Click the `print` icon, then select `Article Format`\n",
        "\n",
        "* Step 7: If your `print dialogue opens`, click `cancel`\n",
        "\n",
        "* Step 8: From the `print preview page`, type `command` + `u` from your keyboard. An HTML view should open\n",
        "\n",
        "* Step 9: From the HTML view, `select all` the text and then `copy` it\n",
        "\n",
        "* Step 10: `Paste` the HTML code into the `html_code` variable in the `Google Colab worksheet`\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MPEZAoZqbnuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "html_code = \"\"\" Paste html here \"\"\""
      ],
      "metadata": {
        "id": "56l2ZC4Xb0bD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob # used to find all the file paths that match a specified pattern\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Hog4SdWceLFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "r9ye5YkcFJsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "create new factiva folder"
      ],
      "metadata": {
        "id": "M5_mCnzbTBTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# ✅ Give your folder a clear name — e.g., use your initials or project topic\n",
        "FOLDER_NAME = \"factiva_ner_project\"\n",
        "\n",
        "# Build the full path\n",
        "DRIVE_ROOT = \"/content/drive/MyDrive\"\n",
        "path = os.path.join(DRIVE_ROOT, FOLDER_NAME)\n",
        "\n",
        "# Create the folder if it doesn’t exist\n",
        "os.makedirs(path, exist_ok=True)\n",
        "\n",
        "print(f\"✅ Folder ready at: {path}\")\n"
      ],
      "metadata": {
        "id": "r4czxfuatEcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, you want to save the contents of the `html_code` variable into a `.htm` file:"
      ],
      "metadata": {
        "id": "gwezETiQOE1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Write the HTML code to the file\n",
        "with open(f\"{path}/factiva.htm\", 'w') as file: #replace with your path\n",
        "    file.write(html_code)\n",
        "\n",
        "\n",
        "# # For a list of variables with HTML content\n",
        "# html_list = [html_code1, html_code2, html_code3]  # Replace with your actual variables\n",
        "\n",
        "# # Iterate over the list and write each HTML content to a separate file\n",
        "# for i, html_code in enumerate(html_list):\n",
        "#     file_path = f\"/content/drive/MyDrive/Factiva/factiva_{i}.htm\"  # Replace with your path\n",
        "#     with open(file_path, 'w') as file:\n",
        "#         file.write(html_code)\n",
        "\n"
      ],
      "metadata": {
        "id": "M04OTM-rb555"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following line, you will look for all `.htm` files in your Factiva folder (and its subfolders, if any) located at the specified path on your Google Drive and return them as a list.\n",
        "\n",
        "- glob.glob is a function that finds all the files that match a specific pattern. In this case, it looks for files inside a folder called Factiva that have the .htm extension.\n",
        "- The part `/content/drive/MyDrive/Factiva/*.htm` is the path where it will look for the files. You would replace this with the path where your own files are located. The *.htm means it will find all files ending with .htm (which are likely HTML files).\n",
        "- recursive = True allows the function to search within subdirectories inside the Factiva folder as well.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EF3WgG0NOUFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "files = glob.glob(f\"{path}/*.htm\", recursive = True) #replace with your path"
      ],
      "metadata": {
        "id": "1ieT2hcrFn3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoDNGSP7A8eL"
      },
      "outputs": [],
      "source": [
        "files"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following `for loop` starts with an empty list. It then goes through each HTML file in the files list, reads any tables found in those files, and adds them to the empty_list.\n",
        "\n",
        "In this case, the goal is to have a list where each element is a dataframe, not a list of lists. Since `pd.read_html()` returns a list of dataframes for each file, `extend` is used to merge those dataframes directly into `empty_list` so that it contains all the dataframes in one flat structure.\n",
        "\n",
        "If you used `append`, you would end up with a nested structure where each element is a list of dataframes, which is likely not what you want."
      ],
      "metadata": {
        "id": "CfP8xPODQflX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tjD6vN0A8eL"
      },
      "outputs": [],
      "source": [
        "empty_list = []\n",
        "for file in files:\n",
        "    data = pd.read_html(file, index_col = 0) #reads the HTML content of the file and tries to find any tables inside it.\n",
        "    empty_list.extend(data) # The extend() method is used to add the data (which is a list of dataframes) from the current file to empty_list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBqYJq0QA8eM",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "empty_list"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a variable, `frames`, which contains a dataframe where all relevant dataframes (those containing 'HD' in their index) are combined and flipped.\n",
        "\n",
        "In the next line of code, we will accomplish the following:\n",
        "- Look through all the dataframes in `empty_list` and selects only the ones where `HD` is found in the index.\n",
        "- Concatenate those dataframes side by side (combining their columns).\n",
        "- Finally, transpose the resulting dataframe, flipping the rows and columns, and assigning it to the variable `frames`.\n",
        "\n",
        "\n",
        "Breaking it down:\n",
        "- `[l for l in empty_list if 'HD' in l.index.values]:`\n",
        "1. This is a list comprehension. It goes through each item `l` in `empty_list` (which contains dataframes).\n",
        "2. For each dataframe `l`, it checks if `'HD'` is present in the index values of that dataframe `(l.index.values)`.\n",
        "3. If `'HD'` is found in the index of a dataframe, that dataframe is included in the resulting list. If `'HD'` is not found, that dataframe is ignored.\n",
        "\n",
        "- `pd.concat([...], axis=1)`:\n",
        "\n",
        "1. this concatenates (joins) all the dataframes that contain `'HD'` in their index. The `axis=1` argument means the dataframes will be concatenated side by side, meaning their columns will be combined.The result is a new dataframe where the data from each matching dataframe is merged by columns.\n",
        "\n",
        "- `.T`:\n",
        "1. This is a shorthand for \"transpose,\" which flips the rows and columns of the resulting dataframe.\n",
        "2. After concatenating the dataframes side by side, `.T` switches the rows and columns, so what were previously columns are now rows, and vice versa."
      ],
      "metadata": {
        "id": "rzjywplSRxIO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMiFyGxFA8eM"
      },
      "outputs": [],
      "source": [
        "frames = pd.concat([l for l in empty_list if 'HD' in l.index.values], axis=1).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7dWVPRlA8eM"
      },
      "outputs": [],
      "source": [
        "frames"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take a look at the columns in our `frames` dataframe. The columns correspond to the index on the left column of the print view of articles in Factiva."
      ],
      "metadata": {
        "id": "qYa1V9u3UI__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frames.columns"
      ],
      "metadata": {
        "id": "9I2UP5iIUISD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's rename certain columns to more meaningful or readable names (e.g., 'HD' becomes 'Headline', 'PD' becomes 'Publication_Date', etc.) and select only the relevant columns we want to keep."
      ],
      "metadata": {
        "id": "Bph-LCAFTw-h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nWDYnhuA8eN"
      },
      "outputs": [],
      "source": [
        "frames.rename(columns = {'HD': 'Headline',\n",
        "                         'PD': 'Publication_Date','SN': 'Source_Name', 'LP': 'Lead Paragraph',\n",
        "                          'TD': 'Body',\n",
        "                         'BY':'Author_Name'}, inplace=True)\n",
        "\n",
        "frames = frames[['Headline', 'Publication_Date', 'Source_Name', 'Lead Paragraph', 'Body', 'Author_Name']]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's make sure our `Publication_Date` column is in datetime format."
      ],
      "metadata": {
        "id": "rewhDm1nT9as"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyleltLKA8eN"
      },
      "outputs": [],
      "source": [
        "frames['Publication_Date'] = pd.to_datetime(frames['Publication_Date'])\n",
        "frames.sort_values(by='Publication_Date', inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we want to combine the text from the `Lead Paragraph` and the `Body` columns so we have the full article in a single cell."
      ],
      "metadata": {
        "id": "4lDj0U8MVOJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frames['CombinedText'] = frames['Lead Paragraph'] + \" \" + frames['Body']"
      ],
      "metadata": {
        "id": "6-VXXSniMSBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frames"
      ],
      "metadata": {
        "collapsed": true,
        "id": "XHPcepOAWQSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's reset the index so it's the standard [0:] index, in ascending order."
      ],
      "metadata": {
        "id": "JaXGedRLWXxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = frames.reset_index()"
      ],
      "metadata": {
        "id": "ZHm89i49fO7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = os.path.join(path, \"factiva.csv\")\n",
        "df.to_csv(save_path, index=False)"
      ],
      "metadata": {
        "id": "Voawf37qupkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we will us a code that loops through each row in the DataFrame `df`, creates a unique text file for each row, and writes the content from the `CombinedText` column into that file. If the `CombinedText` value is missing (i.e., `NaN`), it writes an empty string instead. The filenames are generated dynamically based on the row index.\n",
        "\n",
        "In essence, it saves the text content from each row in the DataFrame as individual text files.\n",
        "\n",
        "1. **`for index, row in df.iterrows():`**\n",
        "   - This line starts a loop over each row in the DataFrame `df`.\n",
        "   - `df.iterrows()` is a pandas function that allows you to loop through the DataFrame row by row.\n",
        "   - `index` represents the row number (starting from 0), and `row` contains the data for that specific row in the form of a pandas Series.\n",
        "\n",
        "2. **`file_name = f\"{path}/text_file_{index + 1}.txt\"`**\n",
        "   - This line generates a unique filename for each row.\n",
        "   - The `f\"{path}/text_file_{index + 1}.txt\"` uses an f-string to create a file name based on the `index` (plus 1 to make it start at 1 instead of 0).\n",
        "   - `path` is a variable that contains the directory where the file will be saved (it should be defined earlier in the code).\n",
        "   - For example, for the first row (index 0), this would create a filename like `\"path/to/directory/text_file_1.txt\"`.\n",
        "\n",
        "3. **`with open(file_name, 'w') as file:`**\n",
        "   - This opens a file with the name `file_name` in write mode (`'w'`), allowing the program to write data into it.\n",
        "   - The `with` statement ensures the file is properly closed after writing, even if an error occurs.\n",
        "\n",
        "4. **`text_content = str(row['CombinedText']) if pd.notnull(row['CombinedText']) else ''`**\n",
        "   - This checks the value in the `'CombinedText'` column for the current row.\n",
        "   - **`pd.notnull(row['CombinedText'])`** checks if the value is **not** `NaN` (i.e., it’s not missing).\n",
        "   - If the value is **not** `NaN`, it converts the value to a string using `str(row['CombinedText'])`.\n",
        "   - If the value is `NaN`, it sets `text_content` to an empty string (`''`).\n",
        "   - This ensures that no matter what value is in the `CombinedText` column, you will have valid text to write to the file (either the text itself or an empty string).\n",
        "\n",
        "5. **`file.write(text_content)`**\n",
        "   - This writes the `text_content` (the string version of the `CombinedText` value) to the file.\n",
        "   - If the `CombinedText` was `NaN`, it writes an empty string; otherwise, it writes the actual content from that column.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VOmnMvjjYcZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for index, row in df.iterrows():\n",
        "    file_name = f\"{path}/factiva/text_file_{index + 1}.txt\"  # Create a unique filename for each row\n",
        "    with open(file_name, 'w') as file:\n",
        "        text_content = str(row['CombinedText']) if pd.notnull(row['CombinedText']) else ''  # Convert to string and handle NaN\n",
        "        file.write(text_content)  # Write the text content to the file"
      ],
      "metadata": {
        "id": "jv2Cw3f9XJtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LjqNJJ1WslSt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}